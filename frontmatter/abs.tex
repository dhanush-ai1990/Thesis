\newpage
\TOCadd{Abstract}
\begin{center}
\textbf{ABSTRACT}
\end{center}

Semantics is the study of meaning and here we explore it through three major representations: brain, image and text. Researchers in the past have performed various studies to understand
the similarities between semantic features across all the three representations.
Distributional Semantic (DS) models  or word vectors that are trained on text corpora
have been widely used to study the convergence of semantic information in human brain. Moreover, they have been incorporated into various NLP applications
such as document categorization, speech to text and machine translation. Due to
their widespread adoption by researchers and industry alike, it becomes imperative
to test and evaluate the performance of different word vectors models. In this thesis, we publish the second iteration of BrainBench: a system designed to evaluate and benchmark word vectors using brain data by incorporating two new Italian brain datasets collected using fMRI and EEG
technology. 

In the second half of the thesis, we explore semantics in Convolutional Neural Network (CNN). CNN is a computational model
that is the state of the art technology for object recognition from images.
However, these networks are currently considered a black-box and there is an apparent lack of understanding on why various CNN architectures
perform better than the other. In this thesis, we also propose a novel method
to understand CNNs by studying the semantic representation through its hierarchical layers. The convergence of semantic information in these networks is studied with
the help of DS models following similar methodologies used to study semantics in the human brain. Our results provide substantial evidence that Convolutional Neural Networks do learn semantics from the images, and the features learned by the CNNs correlate to the semantics
of the object in the image. Our methodology and results could potentially pave the way for improved design and debugging of CNNs.